{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning Introduction\n",
    "\n",
    "就是把foward loss定义写在固定在function里，剩下的它会自己跑\n",
    "Welcome to the introduction to [`PyTorchLightning`](https://www.pytorchlightning.ai/). PyTorch Lightning is a wrapper for PyTorch that is focused towards building neural networks model quickly by removing the boilerplate code. It also extends the functionality of PyTorch, for example, with model Callbacks and automatic porting to GPU to accelerate computations.\n",
    "\n",
    "In its essence, pytorch lightning provides a controlled setup where you are forced to in its specific partly automated library setup, but are able to customize/de-automatate each process if you so desire. You can both rely on a variety of already implemented functionalities and the fact that your code is by definition structured clearly, but at the cost of having to delve into their code structure and figuring out which functions to use.\n",
    "\n",
    "Our suggestion is to try it out. If you like it, cool, otherwise you can just stick to pytorch and build up your own library of functions you will use throughout your Deep Learning journey.\n",
    "\n",
    "Let's get started by installing PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Mount folder in Colab\n",
    "\n",
    "Uncomment thefollowing cell to mount your gdrive if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of six failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 480, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 310, in update_class\n",
      "    old_obj = getattr(old, key)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/six.py\", line 98, in __get__\n",
      "    setattr(obj, self.name, result)  # Invokes __set__.\n",
      "AttributeError: 'NoneType' object has no attribute 'cStringIO'\n",
      "]\n",
      "[autoreload of setuptools._distutils failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 166, in reload\n",
      "    spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/_distutils_hack/__init__.py\", line 97, in find_spec\n",
      "    return method()\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/_distutils_hack/__init__.py\", line 129, in spec_for_distutils\n",
      "    'distutils', DistutilsLoader(), origin=mod.__file__\n",
      "AttributeError: module 'distutils' has no attribute '__file__'\n",
      "]\n",
      "/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "[autoreload of pkg_resources failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 3095, in <module>\n",
      "    class RequirementParseError(packaging.requirements.InvalidRequirement):\n",
      "AttributeError: module 'pkg_resources._vendor.packaging' has no attribute 'requirements'\n",
      "]\n",
      "[autoreload of setuptools._reqs failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/setuptools/_reqs.py\", line 1, in <module>\n",
      "    import setuptools.extern.jaraco.text as text\n",
      "ImportError: cannot import name 'text' from 'setuptools._vendor.jaraco' (/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/setuptools/_vendor/jaraco/__init__.py)\n",
      "]\n",
      "[autoreload of setuptools failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/setuptools/__init__.py\", line 36, in <module>\n",
      "    __version__ = setuptools.version.__version__\n",
      "AttributeError: module 'setuptools' has no attribute 'version'\n",
      "]\n",
      "[autoreload of numpy.core.multiarray failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/multiarray.py\", line 16, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name 'from_dlpack' from 'numpy.core._multiarray_umath' (/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so)\n",
      "]\n",
      "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/numeric.py\", line 10, in <module>\n",
      "    from .multiarray import (\n",
      "ImportError: cannot import name 'from_dlpack' from 'numpy.core.multiarray' (/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/multiarray.py)\n",
      "]\n",
      "[autoreload of numpy.core._add_newdocs failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/_add_newdocs.py\", line 1598, in <module>\n",
      "    add_newdoc('numpy.core.multiarray', 'from_dlpack',\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/function_base.py\", line 521, in add_newdoc\n",
      "    new = getattr(__import__(place, globals(), {}, [obj]), obj)\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute 'from_dlpack'\n",
      "]\n",
      "[autoreload of numpy.linalg.linalg failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/linalg/linalg.py\", line 85, in <module>\n",
      "    _linalg_error_extobj = _determine_error_states()\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/linalg/linalg.py\", line 78, in _determine_error_states\n",
      "    with errstate(invalid='call', over='ignore',\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/_ufunc_config.py\", line 432, in __enter__\n",
      "    self.oldcall = seterrcall(self.call)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/_ufunc_config.py\", line 305, in seterrcall\n",
      "    raise ValueError(\"Only callable can be used as callback\")\n",
      "ValueError: Only callable can be used as callback\n",
      "]\n",
      "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/matrixlib/__init__.py\", line 6, in <module>\n",
      "    __all__ = defmatrix.__all__\n",
      "NameError: name 'defmatrix' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 17, in <module>\n",
      "    from numpy.core._multiarray_umath import _load_from_filelike\n",
      "ImportError: cannot import name '_load_from_filelike' from 'numpy.core._multiarray_umath' (/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so)\n",
      "]\n",
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/lib/__init__.py\", line 44, in <module>\n",
      "    __all__ += type_check.__all__\n",
      "NameError: name 'type_check' is not defined\n",
      "]\n",
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/__init__.py\", line 191, in <module>\n",
      "    core.numerictypes.typeDict,\n",
      "  File \"/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/__init__.py\", line 161, in __getattr__\n",
      "    raise AttributeError(f\"Module {__name__!r} has no attribute {name!r}\")\n",
      "AttributeError: Module 'numpy.core' has no attribute 'numerictypes'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\nimport os\\n\\ngdrive_path='/content/gdrive/MyDrive/i2dl/exercise_07'\\n\\n# This will mount your google drive under 'MyDrive'\\ndrive.mount('/content/gdrive', force_remount=True)\\n# In order to access the files in this notebook we have to navigate to the correct folder\\nos.chdir(gdrive_path)\\n# Check manually if all files are present\\nprint(sorted(os.listdir()))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_07'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "print(sorted(os.listdir()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install correct libraries in google colab\n",
    "# !python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !python -m pip install tensorboard==2.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# For automatic file reloading as usual\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# For google colab\n",
    "# !python -m pip install pytorch-lightning==1.6.0 > /dev/null\n",
    "\n",
    "# For anaconda/regular python\n",
    "# !{sys.executable} -m pip install --ignore-installed pytorch-lightning==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elaine/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/getlimits.py:492: UserWarning: Signature b'f\\xae' for <class 'numpy.float16'> does not match any known type: falling back to type probe function\n",
      "  machar = _get_machar(dtype)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MachAr' object has no attribute '_str_smallest_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/elaine/Desktop/i2dl/i2dl exercise/exercise_07/3_pytorch_lightning.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elaine/Desktop/i2dl/i2dl%20exercise/exercise_07/3_pytorch_lightning.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elaine/Desktop/i2dl/i2dl%20exercise/exercise_07/3_pytorch_lightning.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLightning version: \u001b[39m\u001b[39m{\u001b[39;00mpl\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elaine/Desktop/i2dl/i2dl%20exercise/exercise_07/3_pytorch_lightning.ipynb#ch0000007?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pl\u001b[39m.\u001b[39m__version__\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m1.6\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/i2dl/lib/python3.10/site-packages/pytorch_lightning/__init__.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     _logger\u001b[39m.\u001b[39maddHandler(logging\u001b[39m.\u001b[39mStreamHandler())\n\u001b[1;32m     28\u001b[0m     _logger\u001b[39m.\u001b[39mpropagate \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer  \u001b[39m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/i2dl/lib/python3.10/site-packages/pytorch_lightning/callbacks/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdevice_stats_monitor\u001b[39;00m \u001b[39mimport\u001b[39;00m DeviceStatsMonitor\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mearly_stopping\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n",
      "File \u001b[0;32m~/miniforge3/envs/i2dl/lib/python3.10/site-packages/pytorch_lightning/callbacks/base.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m Optimizer\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m STEP_OUTPUT\n\u001b[1;32m     28\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCallback\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    Abstract base class used to build new callbacks.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39m    Subclass this class and override any of the relevant hooks\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/i2dl/lib/python3.10/site-packages/pytorch_lightning/utilities/__init__.py:67\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparsing\u001b[39;00m \u001b[39mimport\u001b[39;00m AttributeDict, flatten_dict, is_picklable  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrank_zero\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     rank_zero_deprecation,\n\u001b[1;32m     62\u001b[0m     rank_zero_info,\n\u001b[1;32m     63\u001b[0m     rank_zero_only,\n\u001b[1;32m     64\u001b[0m     rank_zero_warn,\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m FLOAT16_EPSILON \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfinfo(numpy\u001b[39m.\u001b[39;49mfloat16)\u001b[39m.\u001b[39meps\n\u001b[1;32m     68\u001b[0m FLOAT32_EPSILON \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfinfo(numpy\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39meps\n\u001b[1;32m     69\u001b[0m FLOAT64_EPSILON \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfinfo(numpy\u001b[39m.\u001b[39mfloat64)\u001b[39m.\u001b[39meps\n",
      "File \u001b[0;32m~/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/getlimits.py:485\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    484\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[0;32m--> 485\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49m_init(dtype)\n\u001b[1;32m    486\u001b[0m \u001b[39mfor\u001b[39;00m dt \u001b[39min\u001b[39;00m dtypes:\n\u001b[1;32m    487\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_finfo_cache[dt] \u001b[39m=\u001b[39m obj\n",
      "File \u001b[0;32m~/miniforge3/envs/i2dl/lib/python3.10/site-packages/numpy/core/getlimits.py:512\u001b[0m, in \u001b[0;36mfinfo._init\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_str_eps \u001b[39m=\u001b[39m machar\u001b[39m.\u001b[39m_str_eps\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_str_resolution \u001b[39m=\u001b[39m machar\u001b[39m.\u001b[39m_str_resolution\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m--> 512\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_str_smallest_normal \u001b[39m=\u001b[39m machar\u001b[39m.\u001b[39;49m_str_smallest_normal\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    513\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_str_smallest_subnormal \u001b[39m=\u001b[39m machar\u001b[39m.\u001b[39m_str_smallest_subnormal\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    514\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MachAr' object has no attribute '_str_smallest_normal'"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "print(f\"Lightning version: {pl.__version__}\")\n",
    "if not pl.__version__.startswith(\"1.6\"):\n",
    "    print(\"You are using another version of pytorch lightning. We expect pytorch lightning 1.6.0. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "\n",
    "import tensorboard\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"Tensorboard version: {tensorboard.__version__}\")\n",
    "if not tensorboard.__version__.startswith(\"2.9.1\"):\n",
    "    print(\"You are using an another version of Tensorboard. We expect Tensorboard 2.9.1 You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
    "if not torch.__version__.startswith(\"1.11\"):\n",
    "    print(\"you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "if not torchvision.__version__.startswith(\"0.12\"):\n",
    "    print(\"you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Idea behind PyTorch Lightning\n",
    "\n",
    "Codes in a Deep learning project consists of three main categories:\n",
    "\n",
    "1. **Research code**   \n",
    "    This is the exciting part of the experiment where you configure the model architecture and try out different optimizers and target task. This is managed by the `LightningModule` of PyTorch Lightning.\n",
    "    \n",
    "2. **Engineering code**  \n",
    "    This is the same set of code that remain the same for all deep learning projects.Recall the training block of previous notebooks where we loop through the epochs and mini-batches. The `Trainer` class of PyTorch Lightning takes care of this part of code.\n",
    "    \n",
    "3. **Non-essential code**\n",
    "    It is very important that we log our training metrics and organize different training runs to have purposeful experimentation of models. The `Callbacks` class PyTorch Lightning helps us with this section. \n",
    "\n",
    "Let's look at each of these modules in detail.\n",
    "\n",
    "1. **LightningModules** contain all model related code. This is the part where we are working on when creating a new project. The idea is to have all important code in one module, e.g., the model's architecture and the evaluation of training and validation metrics. This provides a better overview as repeated elements, such as the training procedure, are not stored in the code that we work on. The lightning module also handles the calls `.to(device)` or `.train()` and `.eval()`. Hence, there is no need anymore to switch between the cpu and gpu and to take care of the model's mode as this is automated by the LightningModule. The framework also enables easy parallel computation on multiple gpus. \n",
    "\n",
    "2. **Trainer** contains all code needed for training our neural networks that doesn't change for each project (\"one size fits all\"). Usually, we don't touch the code automated by this class. The arguments that are specific for one training such as learning rate and batch size are provided as initialization arguments for the LightningModule.\n",
    "\n",
    "3. **Callbacks** automate all parts needed for logging hyperparameters or training results such as the tensorboard logger. Logging becomes very important for research later since the results of experiments need to be reproducible.\n",
    "\n",
    "All in all, PyTorch is a framework that handles all (annoying) \"engineering\" stuff for you such that you have more time for exciting research and scientific coding. This also results in the advantage that automated parts are guaranteed to be bug-free. Hence, you can't include a bug in a part of your code that is often used but not often checked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Overview of the PyTorch Lightning code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research relevant code goes into the `LightningModule`. The advantage is that we have all the model building, training & validation steps within a single class. These are the components that usually change based on the projects and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorBoard Interface](./images/pl_quick_start_full_compressed.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining code is automated by the `Trainer` class which takes care of the tasks of our mechanical training loops components such as iterating through the minibatches and gradient updating steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/700/1*b81_j__xv8M0Bb6nFTXbAA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could already see how much more readable and concise our code is, after being transformed by PyTorch Lightning.\n",
    "\n",
    "Let us now train a neural network model with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training with PyTorch Lightning\n",
    "\n",
    "We will build a two-layer neural network to train on the the [`Fashion-MNIST`](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset for this notebook. \n",
    "\n",
    "## 4.1 Define A LightningModule\n",
    "\n",
    "We define our network as an instance of `pl.LightningModule` which replaces our `PyTorch` network based on the class `nn.Module`. Additionally, it contains all the relevant parts that are used for training and evaluating different models on various tasks.  \n",
    "\n",
    "Let's have a look at the implementation of `TwoLayerNet` in `exercise_code.lightning_models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__init__()` and `forward()` function defining the forward  pass remain the same. Hence, we can just copy the code from the `nn.Module`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义Net，1.继承LightningModule，2.重写一些必须的function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class TwoLayerNet(pl.LightningModule):\n",
    "    def __init__(self, hparams, input_size=1 * 28 * 28, hidden_size=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the image  before sending as input to the model\n",
    "        N, _, _, _ = x.shape\n",
    "        x = x.view(N, -1)\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now **define the training and validation steps** since they also vary with different tasks and projects. Consequently, it is useful to integrate these parts into our instance of `LightningModule`. Validation loss is returned for each validation mini-batch and averaged at the end of the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "\n",
    "        # Perform a forward pass on the network with inputs\n",
    "        out = self.forward(images)\n",
    "\n",
    "        # calculate the loss with the network predictions and ground truth targets\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        # Find the predicted class from probabilities of the image belonging to each of the classes\n",
    "        # from the network output\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        # Calculate the accuracy of predictions\n",
    "        acc = preds.eq(targets).sum().float() / targets.size(0)\n",
    "\n",
    "        # Log the accuracy and loss values to the tensorboard\n",
    "        self.log('loss', loss)\n",
    "        self.log('acc', acc)\n",
    "\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "\n",
    "        # Perform a forward pass on the network with inputs\n",
    "        out = self.forward(images)\n",
    "\n",
    "        # calculate the loss with the network predictions and ground truth targets\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        # Find the predicted class from probabilities of the image belonging to each of the classes\n",
    "        # from the network output\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        # Calculate the accuracy of predictions\n",
    "        acc = preds.eq(targets).sum().float() / targets.size(0)\n",
    "\n",
    "        # Visualise the predictions  of the model\n",
    "        if batch_idx == 0:\n",
    "            self.visualize_predictions(images, out.detach(), targets)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        # Average the loss over the entire validation data from it's mini-batches\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "\n",
    "        # Log the validation accuracy and loss values to the tensorboard\n",
    "        self.log('val_loss', avg_loss)\n",
    "        self.log('val_acc', avg_acc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step missing in our `LightningModule` is the optimizer. This method needs to be defined in every `LightningModule`. Optimizer = 迭代W的算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.model.parameters(), self.hparams[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "        return optim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set up the model and the training steps, we will now establish the data pipeline. PyTorch Lightning provides the `LightningDataModule` for setting up the dataloaders.\n",
    "\n",
    "Let's have a look at the implementation of `FashionMNISTDataModule` in `exercise_code.data_class`.\n",
    "\n",
    "The `prepare_data()` function intends to set up the dataset and the related transforms for it. As previously, we download the `FashionMNIST` dataset using `torchvision` and split the total training data into a training and validation set for tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class FashionMNISTDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, batch_size=4):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        # Define the transform\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Download the Fashion-MNIST dataset\n",
    "        fashion_mnist_train_val = torchvision.datasets.FashionMNIST(root='../datasets', train=True,\n",
    "                                                                   download=True, transform=transform)\n",
    "\n",
    "        self.fashion_mnist_test = torchvision.datasets.FashionMNIST(root='../datasets', train=False,\n",
    "                                                                 download=True, transform=transform)\n",
    "\n",
    "        # Apply the Transforms\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Perform the training and validation split\n",
    "        self.train_dataset, self.val_dataset = random_split(\n",
    "            fashion_mnist_train_val, [50000, 10000])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now define `Dataloaders` for each of the data-splits. These data loaders can be directly called during model training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.fashion_mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice now that most of the code of these steps can be directly copied from a Vanilla PyTorch code. Lightning just rearranges them. This marks the end of the research part of the code.\n",
    "\n",
    "Let's see now how the `Trainer` class works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.2 Fitting the model with a Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize the model and the data  with a set of hyperparameters given in the dictionary `hparams`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "\n",
    "from exercise_code.lightning_models import TwoLayerNet\n",
    "from exercise_code.data_class import FashionMNISTDataModule\n",
    "\n",
    "hparams = {\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"input_size\": 1 * 28 * 28,\n",
    "    \"hidden_size\": 512,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_workers\": 2,    # used by the dataloader, more workers means faster data preparation, but for us this is not a bottleneck here\n",
    "}\n",
    "\n",
    "\n",
    "model = TwoLayerNet(hparams)\n",
    "data=FashionMNISTDataModule(hparams)\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PyTorch Lightning provides ample flexibility for training using [`Trainer`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html) class.\n",
    "Have a look at the documentation to know more about them!\n",
    "\n",
    "Let's initialize it now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    # Uncomment to use GPU if available, if multiple you can select all indices, otherwise we use the first, -1 is CPU\n",
    "    # devices='0' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `max_epochs` sets the maximum number of epochs for training. \n",
    "The argument `weights_summary` prints a summary of the number of weights per layer at the beginning of the training. Set it to None if the summary is not required.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the actual training cell. The [`fit`](https://pytorch-lightning.readthedocs.io/en/latest/_modules/pytorch_lightning/trainer/trainer.html#Trainer.fit) function takes in the model and data to train the model with a lot more optional arguments for customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout the directory `lightning_logs`. For each run there is a new directory `version_xx` created. The rightmost argument in the progress bar, the `v_num` variable above shows the version of the current run. Each directory automatically contains a folder with checkpoints, logs and the hyperparameters for this run.\n",
    "\n",
    "As seen in the last notebook, you can have a look at the  logs of the runs in the TensorBoard  \n",
    "Use the command as in the previous notebook in your terminal \n",
    "```\n",
    "tensorboard --logdir lightning_logs\n",
    "```\n",
    "Make sure to use the above command as the same directory as `exercise_07`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, run the following cell to load the TensorBoard extension within the notebook. You may have to scroll to this block whenever you need to look at the TensorBoard interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Add images to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorboard logger is a submodule of the `LightningModule` and can be accessed via `self.logger`. We can  add images  to the logging module by calling \n",
    "```python\n",
    "self.logger.experiment.add_image('tag', image)\n",
    "```\n",
    "to add an image. \n",
    "\n",
    "\n",
    "We will log the first batch of validation images in a grid together with the predicted class labels and the ground truth labels. \n",
    "\n",
    "```python\n",
    "        if batch_idx == 0:\n",
    "            self.visualize_predictions(images, out.detach(), targets)\n",
    "```\n",
    "\n",
    "Let's have a look at the implementation of `visualize_predictions()` function in `exercise_code.lightning_models`.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    def visualize_predictions(self, images, preds, targets):\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "        # determine size of the grid based on given batch size\n",
    "        num_rows = torch.tensor(len(images)).float().sqrt().floor()\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        for i in range(len(images)):\n",
    "            plt.subplot(num_rows ,len(images) // num_rows + 1, i+1)\n",
    "            plt.imshow(images[i].permute(1, 2, 0))\n",
    "            plt.title(class_names[torch.argmax(preds, axis=-1)[i]] + f'\\n[{class_names[targets[i]]}]')\n",
    "            plt.axis('off')\n",
    "\n",
    "        self.logger.experiment.add_figure('predictions', fig, global_step=self.global_step)\n",
    "```\n",
    "\n",
    "You can view the logged images in your `IMAGES` tab of TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now looked at how to train a model using PyTorch Lightning. PyTorch Lightning is very active in developement and the features set are continously expanded and updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Other Features of PyTorch Lightning\n",
    "\n",
    "\n",
    "### Checking  training timings\n",
    "\n",
    "The argument `profiler` of the `Trainer` class measures the time taken in different steps such as dataloading, forward and backward pass. You can select a variety of loggers [here](https://pytorch-lightning.readthedocs.io/en/stable/advanced/profiler.html).\n",
    "\n",
    "Run the cell below to see for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    profiler='simple',\n",
    "    max_epochs=1,\n",
    "    # gpus=1 # Use GPU if available\n",
    "   \n",
    ")\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an overview of the time taken for different steps.\n",
    "This  enables us to detect bottlenecks in the model more easily. A bottleneck can be, for example, long times in dataloading. It becomes very important later, especially, when you start to implement custom layers or loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more debugging Options\n",
    "\n",
    "* [`fast_dev_run`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#fast-dev-run): Runs of batch of each train, validation and test pass (if validation and test datalaoders are passed as arguments).This is a fast way to check if everything works (dataloading, validation metric, model saving/ loading) without having to wait for a full epoch.\n",
    "\n",
    "* [`track_grad_norm`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#track-grad-norm): Logs the  norm of the gradients (set to `1` for the $L1$ norm or `2` for the $L2$ norm) for each layer. You can check whether the network is actually doing something. If the gradients are too small or too high, you won't have a good training (due to vanishing/ exploding gradients).\n",
    "\n",
    "\n",
    "### Other Features\n",
    "\n",
    "Finally, we want to mention some other useful options in the Trainer class:\n",
    "\n",
    "* [`resume_from_checkpoint`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#resume-from-checkpoint): Start the training from a checkpoint saved earlier. Argument is the path to the saved model file.\n",
    "* [`Callbacks`](https://pytorch-lightning.readthedocs.io/en/latest/callbacks.html#callback): Callbacks are extremely useful system during training that automate non essential code such as  storing model checkpoints , saving weights values among others.\n",
    "\n",
    "Let's have the look at the [`EarlyStopping`](https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html#early-stopping-based-on-metric-using-the-earlystopping-callback)  callback.\n",
    "\n",
    "It interrupts the training if the `monitor` metric variable does not  improve for `patience` number of epochs.\n",
    "\n",
    "Below is a code example on how to apply it!\n",
    "\n",
    "```python\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=10,callbacks=[early_stop_callback])\n",
    "```\n",
    "\n",
    "Your journey with pytorch lightning will force you to check out a bunch of callbacks to return the desired functions without having to write the respective code yourself. Or you hack it in, do as you wish :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. PyTorch Lightining [`Source Code`](https://github.com/PyTorchLightning/pytorch-lightning) with a nice introduction \n",
    "2. PyTorch Lightining [`Documentation`](https://pytorch-lightning.readthedocs.io/en/latest/#)  Explore it! The features are very well explained. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('i2dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c35ef51b8ea5833cecc11f44390ce192ec2bcce37c333f05f27cbb87ba6d9ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
